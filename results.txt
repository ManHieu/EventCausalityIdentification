F1: 0.5840220380757538 
Hyperparams: 
 {'learning_rate': 0.0005, 'batch_size': 32, 'warmup_ratio': 0.1, 'num_train_epochs': 5, 'datasets': 'ESL', 'model_name_or_path': '/vinai/hieumdt/pretrained_models/models/t5-base-for-conditional-generation', 'tokenizer_name': '/vinai/hieumdt/pretrained_models/tokenizers/t5-base-for-conditional-generation', 'seed': '1741', 'max_seq_length': '256', 'max_output_seq_length': '32'}
-------------------- 
F1: 0.5897435892625771 
Hyperparams: 
 {'p_learning_rate': 0.001, 's_learning_rate': 0.0005, 'batch_size': 32, 'warmup_ratio': 0.1, 'num_train_epochs': 7, 'datasets': 'ESL', 'model_name_or_path': '/vinai/hieumdt/pretrained_models/models/t5-base-for-conditional-generation', 'tokenizer_name': '/vinai/hieumdt/pretrained_models/tokenizers/t5-base-for-conditional-generation', 'selector_name_or_path': '/vinai/hieumdt/pretrained_models/models/t5-encoder-base/', 'seed': '1741', 'max_seq_length': '256', 'max_output_seq_length': '2'}
---------------------
F1: 0.5995953499936382 
P: 0.5882002560389965 
R: 0.5882002560389965 
Hyperparams: 
 {'p_learning_rate': 0.005, 's_learning_rate': 0.001, 'batch_size': 32, 'warmup_ratio': 0.1, 'num_train_epochs': 7, 'kl_weight': 1.0, 'f1_weight': 1.0, 'predict_weight': 1.0, 'reconstruct_weight': 1.0, 'datasets': 'ESL', 'model_name_or_path': '/vinai/hieumdt/pretrained_models/models/t5-base-for-conditional-generation', 'tokenizer_name': '/vinai/hieumdt/pretrained_models/tokenizers/t5-base-for-conditional-generation', 'selector_name_or_path': '/vinai/hieumdt/pretrained_models/models/t5-encoder-base/', 'seed': '1741', 'max_seq_length': '256', 'max_output_seq_length': '64'}
-------------------- 
F1: 0.4930402677250769 
P: 0.5584577459196033 
R: 0.5584577459196033 
Hyperparams: 
 {'p_learning_rate': 0.005, 's_learning_rate': 0.005, 'batch_size': 32, 'warmup_ratio': 0.1, 'num_train_epochs': 3, 'kl_weight': 1.0, 'f1_weight': 0.1, 'predict_weight': 1.0, 'reconstruct_weight': 0.1, 'datasets': 'ESL', 'model_name_or_path': '/vinai/hieumdt/pretrained_models/models/t5-base-for-conditional-generation', 'tokenizer_name': '/vinai/hieumdt/pretrained_models/tokenizers/t5-base-for-conditional-generation', 'selector_name_or_path': '/vinai/hieumdt/pretrained_models/models/t5-encoder-base/', 'seed': '1741', 'max_seq_length': '256', 'max_output_seq_length': '64'}
-------------------- 
F1: 0.6103149585608401 
P: 0.6098411238043483 
R: 0.6119891188800122 
Hyperparams: 
 {'p_learning_rate': 0.005, 's_learning_rate': 0.0005, 'batch_size': 32, 'warmup_ratio': 0.1, 'num_train_epochs': 7, 'kl_weight': 1.0, 'f1_weight': 1.0, 'predict_weight': 1.0, 'reconstruct_weight': 0.1, 'datasets': 'ESL', 'model_name_or_path': '/vinai/hieumdt/pretrained_models/models/t5-base-for-conditional-generation', 'tokenizer_name': '/vinai/hieumdt/pretrained_models/tokenizers/t5-base-for-conditional-generation', 'selector_name_or_path': '/vinai/hieumdt/pretrained_models/models/t5-encoder-base/', 'seed': '1741', 'max_seq_length': '256', 'max_output_seq_length': '64'}
-------------------- 
F1: 0.5985788959715976 
P: 0.6227531898573678 
R: 0.578217762726178 
Hyperparams: 
 {'p_learning_rate': 0.005, 's_learning_rate': 0.001, 'batch_size': 32, 'warmup_ratio': 0.1, 'num_train_epochs': 7, 'kl_weight': 1.0, 'f1_weight': 1.0, 'predict_weight': 1.0, 'reconstruct_weight': 1.0, 'datasets': 'ESL', 'model_name_or_path': '/vinai/hieumdt/pretrained_models/models/t5-base-for-conditional-generation', 'tokenizer_name': '/vinai/hieumdt/pretrained_models/tokenizers/t5-base-for-conditional-generation', 'selector_name_or_path': '/vinai/hieumdt/pretrained_models/models/t5-encoder-base/', 'seed': '1741', 'max_seq_length': '256', 'max_output_seq_length': '64'}
-------------------- 
F1: 0.5036122310731078 
P: 0.5325015952910717 
R: 0.48757380525985666 
Hyperparams: 
 {'p_learning_rate': 0.005, 's_learning_rate': 0.0005, 'batch_size': 32, 'warmup_ratio': 0.1, 'num_train_epochs': 3, 'kl_weight': 1.0, 'f1_weight': 1.0, 'predict_weight': 1.0, 'reconstruct_weight': 0.1, 'datasets': 'ESL', 'model_name_or_path': '/vinai/hieumdt/pretrained_models/models/t5-base-for-conditional-generation', 'tokenizer_name': '/vinai/hieumdt/pretrained_models/tokenizers/t5-base-for-conditional-generation', 'selector_name_or_path': '/vinai/hieumdt/pretrained_models/models/t5-encoder-base/', 'seed': '1741', 'max_seq_length': '256', 'max_output_seq_length': '64'}
-------------------- 
F1: 0.5473218859355756 
P: 0.6028470029269626 
R: 0.5126850095546469 
Hyperparams: 
 {'p_learning_rate': 0.001, 's_learning_rate': 0.005, 'batch_size': 32, 'warmup_ratio': 0.1, 'num_train_epochs': 7, 'kl_weight': 1.0, 'f1_weight': 1.0, 'predict_weight': 1.0, 'reconstruct_weight': 0.1, 'datasets': 'ESL', 'model_name_or_path': '/vinai/hieumdt/pretrained_models/models/t5-base-for-conditional-generation', 'tokenizer_name': '/vinai/hieumdt/pretrained_models/tokenizers/t5-base-for-conditional-generation', 'selector_name_or_path': '/vinai/hieumdt/pretrained_models/models/t5-encoder-base/', 'seed': '1741', 'max_seq_length': '256', 'max_output_seq_length': '64'}
-------------------- 
F1: 0.4790395381484144 
P: 0.5448112791138786 
R: 0.45085795011075913 
Hyperparams: 
 {'p_learning_rate': 0.005, 's_learning_rate': 0.0005, 'batch_size': 32, 'warmup_ratio': 0.1, 'num_train_epochs': 3, 'kl_weight': 1.0, 'f1_weight': 1.0, 'predict_weight': 1.0, 'reconstruct_weight': 1.0, 'datasets': 'ESL', 'model_name_or_path': '/vinai/hieumdt/pretrained_models/models/t5-base-for-conditional-generation', 'tokenizer_name': '/vinai/hieumdt/pretrained_models/tokenizers/t5-base-for-conditional-generation', 'seed': '1741', 'max_seq_length': '256', 'max_output_seq_length': '64'}
-------------------- 
F1: 0.5880649411457968 
P: 0.5831393760417629 
R: 0.5953462898349448 
Hyperparams: 
 {'p_learning_rate': 0.005, 's_learning_rate': 0.0005, 'batch_size': 32, 'warmup_ratio': 0.1, 'num_train_epochs': 7, 'kl_weight': 1.0, 'f1_weight': 1.0, 'predict_weight': 1.0, 'reconstruct_weight': 0.1, 'datasets': 'ESL', 'model_name_or_path': '/vinai/hieumdt/pretrained_models/models/t5-base-for-conditional-generation', 'tokenizer_name': '/vinai/hieumdt/pretrained_models/tokenizers/t5-base-for-conditional-generation', 'seed': '1741', 'max_seq_length': '256', 'max_output_seq_length': '64'}
-------------------- 
F1: 0.6054349763123857 
P: 0.6239270330342088 
R: 0.592702347659095 
Hyperparams: 
 {'p_learning_rate': 0.005, 's_learning_rate': 0.001, 'batch_size': 32, 'warmup_ratio': 0.1, 'num_train_epochs': 7, 'kl_weight': 1.0, 'f1_weight': 1.0, 'predict_weight': 1.0, 'reconstruct_weight': 1.0, 'datasets': 'ESL', 'model_name_or_path': '/vinai/hieumdt/pretrained_models/models/t5-base-for-conditional-generation', 'tokenizer_name': '/vinai/hieumdt/pretrained_models/tokenizers/t5-base-for-conditional-generation', 'seed': '1741', 'max_seq_length': '256', 'max_output_seq_length': '64'}
-------------------- 
F1: 0.43672158314645343 
P: 0.3907563518111826 
R: 0.5074961521823329 
Hyperparams: 
 {'pretrain_lr': 0.001, 'reinforce_lr': 1e-05, 'reconstruct_lr': 1e-05, 'batch_size': 32, 'warmup_ratio': 0.1, 'pretrain_epoches': 3, 'reinforce_train_epoches': 5, 'generate_weight': 0.95, 'f1_weight': 0.9, 'datasets': 'ESL', 'model_name_or_path': '/vinai/hieumdt/pretrained_models/models/t5-base-for-conditional-generation', 'tokenizer_name': '/vinai/hieumdt/pretrained_models/tokenizers/t5-base-for-conditional-generation', 'seed': '1741', 'max_seq_length': '256', 'max_output_seq_length': '64'}
-------------------- 
F1: 0.5880649411457968 
P: 0.5831393760417629 
R: 0.5953462898349448 
Hyperparams: 
 {'p_learning_rate': 0.005, 's_learning_rate': 0.001, 'batch_size': 32, 'warmup_ratio': 0.1, 'num_train_epochs': 7, 'kl_weight': 1.0, 'f1_weight': 1.0, 'predict_weight': 1.0, 'reconstruct_weight': 0.1, 'datasets': 'ESL', 'model_name_or_path': '/vinai/hieumdt/pretrained_models/models/t5-base-for-conditional-generation', 'tokenizer_name': '/vinai/hieumdt/pretrained_models/tokenizers/t5-base-for-conditional-generation', 'seed': '1741', 'max_seq_length': '256', 'max_output_seq_length': '64'}
--------------------
Hyperparams: 
 {'lr': 0.01, 'batch_size': 32, 'warmup_ratio': 0.1, 'num_epoches': 7, 'generate_weight': 0.5, 'mle_weight': 1.0}
F1: 0.5666666661667764 
P: 0.5583941605839416 
R: 0.575187969924812 
-------------------- 
Hyperparams: 
 {'lr': 5e-05, 'batch_size': 32, 'warmup_ratio': 0.1, 'num_epoches': 7, 'generate_weight': 0.5, 'mle_weight': 1.0}
-------------------- 
Hyperparams: 
 {'lr': 0.01, 'batch_size': 32, 'warmup_ratio': 0.1, 'num_epoches': 10, 'generate_weight': 0.75, 'mle_weight': 1.0}
F1: 0.564393938893968 
P: 0.5687022900763359 
R: 0.5601503759398496 
-------------------- 
Hyperparams: 
 {'lr': 0.01, 'batch_size': 32, 'warmup_ratio': 0.1, 'num_epoches': 7, 'generate_weight': 0.5, 'mle_weight': 1.0}
F1: 0.5666666661667764 
P: 0.5583941605839416 
R: 0.575187969924812 
-------------------- 
Hyperparams: 
 {'lr': 0.05, 'batch_size': 32, 'warmup_ratio': 0.1, 'num_epoches': 7, 'generate_weight': 0.5, 'mle_weight': 1.0}
-------------------- 
Hyperparams: 
 {'lr': 0.005, 'batch_size': 32, 'warmup_ratio': 0.1, 'num_epoches': 7, 'generate_weight': 0.5, 'mle_weight': 1.0}
-------------------- 
Hyperparams: 
 {'lr': 0.02, 'batch_size': 32, 'warmup_ratio': 0.1, 'num_epoches': 7, 'generate_weight': 0.75, 'mle_weight': 1.0}
-------------------- 
Hyperparams: 
 {'lr': 0.013, 'batch_size': 32, 'warmup_ratio': 0.1, 'num_epoches': 10, 'generate_weight': 0.75, 'mle_weight': 1.0}
F1: 0.448065172619576 
P: 0.4888888888888889 
R: 0.41353383458646614 
-------------------- 
Hyperparams: 
 {'lr': 0.013, 'batch_size': 32, 'warmup_ratio': 0.1, 'num_epoches': 5, 'generate_weight': 0.9, 'mle_weight': 1.0}
F1: 0.4327731087506179 
P: 0.49047619047619045 
R: 0.38721804511278196 
-------------------- 
Hyperparams: 
 {'lr': 0.02, 'batch_size': 32, 'warmup_ratio': 0.1, 'num_epoches': 10, 'generate_weight': 0.75, 'mle_weight': 1.0}
-------------------- 
Hyperparams: 
 {'lr': 0.006, 'batch_size': 32, 'warmup_ratio': 0.1, 'num_epoches': 5, 'generate_weight': 0.9, 'mle_weight': 1.0}
F1: 0.53549695690678 
P: 0.5814977973568282 
R: 0.49624060150375937 
-------------------- 
Hyperparams: 
 {'lr': 0.014, 'batch_size': 32, 'warmup_ratio': 0.1, 'num_epoches': 20, 'generate_weight': 0.5, 'mle_weight': 1.0}
F1: 0.4028436014297073 
P: 0.5448717948717948 
R: 0.31954887218045114 
-------------------- 
Hyperparams: 
 {'lr': 0.006, 'batch_size': 32, 'warmup_ratio': 0.1, 'num_epoches': 5, 'generate_weight': 0.75, 'mle_weight': 1.0}
F1: 0.49292929243208655 
P: 0.5327510917030568 
R: 0.45864661654135336 
-------------------- 
Hyperparams: 
 {'lr': 0.006, 'batch_size': 32, 'warmup_ratio': 0.1, 'num_epoches': 7, 'generate_weight': 0.75, 'mle_weight': 1.0}
F1: 0.5868055550584732 
P: 0.5451612903225806 
R: 0.6353383458646616 
-------------------- 
Hyperparams: 
 {'lr': 0.012, 'batch_size': 32, 'warmup_ratio': 0.1, 'num_epoches': 5, 'generate_weight': 0.9, 'mle_weight': 1.0}
F1: 0.4670231724068619 
P: 0.4440677966101695 
R: 0.4924812030075188 
-------------------- 
Hyperparams: 
 {'lr': 0.01, 'batch_size': 32, 'warmup_ratio': 0.1, 'num_epoches': 20, 'generate_weight': 0.75, 'mle_weight': 1.0}
F1: 0.4341801380942669 
P: 0.562874251497006 
R: 0.3533834586466165 
-------------------- 
Hyperparams: 
 {'lr': 0.008, 'batch_size': 32, 'warmup_ratio': 0.1, 'num_epoches': 7, 'generate_weight': 0.5, 'mle_weight': 1.0}
F1: 0.5845588230296551 
P: 0.5719424460431655 
R: 0.5977443609022557 
-------------------- 
Hyperparams: 
 {'lr': 0.012, 'batch_size': 32, 'warmup_ratio': 0.1, 'num_epoches': 5, 'generate_weight': 0.5, 'mle_weight': 1.0}
F1: 0.4969696964724906 
P: 0.537117903930131 
R: 0.462406015037594 
-------------------- 
Hyperparams: 
 {'lr': 5e-05, 'batch_size': 16, 'warmup_ratio': 0.1, 'num_epoches': 7, 'f1_reward_weight': 0.25, 'reconstruct_reward_weight': 0.25, 'generate_weight': 1.0, 'mle_weight': 0.5}
F1: 0.5239852393525686 
P: 0.5144927536231884 
R: 0.5338345864661654 
-------------------- 
Hyperparams: 
 {'lr': 0.005, 'batch_size': 16, 'warmup_ratio': 0.1, 'num_epoches': 5, 'f1_reward_weight': 0.5, 'reconstruct_reward_weight': 0.1, 'generate_weight': 1.0, 'mle_weight': 0.5}
F1: 0.5527831089052132 
P: 0.5647058823529412 
R: 0.5413533834586466 
-------------------- 
Hyperparams: 
 {'lr': 0.0005, 'batch_size': 16, 'warmup_ratio': 0.1, 'num_epoches': 7, 'f1_reward_weight': 0.75, 'reconstruct_reward_weight': 0.25, 'generate_weight': 1.0, 'mle_weight': 0.5}
-------------------- 
Hyperparams: 
 {'lr': 5e-05, 'batch_size': 16, 'warmup_ratio': 0.1, 'num_epoches': 5, 'f1_reward_weight': 0.5, 'reconstruct_reward_weight': 0.25, 'generate_weight': 1.0, 'mle_weight': 0.5}
F1: 0.5226337443604464 
P: 0.5772727272727273 
R: 0.4774436090225564 
-------------------- 
Hyperparams: 
 {'lr': 5e-05, 'batch_size': 16, 'warmup_ratio': 0.1, 'num_epoches': 10, 'f1_reward_weight': 0.75, 'reconstruct_reward_weight': 0.25, 'generate_weight': 1.0, 'mle_weight': 0.5}
-------------------- 
Hyperparams: 
 {'lr': 5e-05, 'batch_size': 16, 'warmup_ratio': 0.1, 'num_epoches': 5, 'f1_reward_weight': 0.25, 'reconstruct_reward_weight': 0.25, 'generate_weight': 1.0, 'mle_weight': 0.25}
-------------------- 
Hyperparams: 
 {'lr': 5e-06, 'batch_size': 16, 'warmup_ratio': 0.1, 'num_epoches': 10, 'f1_reward_weight': 0.75, 'reconstruct_reward_weight': 0.1, 'generate_weight': 1.0, 'mle_weight': 0.25}
-------------------- 
Hyperparams: 
 {'lr': 0.0005, 'batch_size': 16, 'warmup_ratio': 0.1, 'num_epoches': 7, 'f1_reward_weight': 0.5, 'reconstruct_reward_weight': 0.1, 'generate_weight': 1.0, 'mle_weight': 0.25}
-------------------- 
Hyperparams: 
 {'lr': 5e-06, 'batch_size': 16, 'warmup_ratio': 0.1, 'num_epoches': 7, 'f1_reward_weight': 0.25, 'reconstruct_reward_weight': 0.25, 'generate_weight': 1.0, 'mle_weight': 0.5}
-------------------- 
Hyperparams: 
 {'lr': 5e-06, 'batch_size': 16, 'warmup_ratio': 0.1, 'num_epoches': 7, 'f1_reward_weight': 0.25, 'reconstruct_reward_weight': 0.1, 'generate_weight': 1.0, 'mle_weight': 0.5}
F1: 0.5661080069488329 
P: 0.5608856088560885 
R: 0.5714285714285714 
-------------------- 
Hyperparams: 
 {'lr': 0.0005, 'batch_size': 16, 'warmup_ratio': 0.1, 'num_epoches': 5, 'f1_reward_weight': 0.5, 'reconstruct_reward_weight': 0.1, 'generate_weight': 1.0, 'mle_weight': 0.25}
F1: 0.6298701293794273 
P: 0.5542857142857143 
R: 0.7293233082706767 
-------------------- 
Hyperparams: 
 {'lr': 0.0005, 'batch_size': 16, 'warmup_ratio': 0.1, 'num_epoches': 10, 'f1_reward_weight': 0.75, 'reconstruct_reward_weight': 0.25, 'generate_weight': 1.0, 'mle_weight': 0.25}
F1: 0.5614035082966212 
P: 0.45933014354066987 
R: 0.7218045112781954 
-------------------- 
Hyperparams: 
 {'lr': 0.005, 'batch_size': 16, 'warmup_ratio': 0.1, 'num_epoches': 7, 'f1_reward_weight': 0.5, 'reconstruct_reward_weight': 0.25, 'generate_weight': 1.0, 'mle_weight': 0.5}
F1: 0.5898778354536943 
P: 0.5504885993485342 
R: 0.6353383458646616 
-------------------- 
Hyperparams: 
 {'lr': 5e-06, 'batch_size': 16, 'warmup_ratio': 0.1, 'num_epoches': 5, 'f1_reward_weight': 0.5, 'reconstruct_reward_weight': 0.25, 'generate_weight': 1.0, 'mle_weight': 0.25}
F1: 0.5651376141791835 
P: 0.5519713261648745 
R: 0.5789473684210527 
-------------------- 
Hyperparams: 
 {'lr': 0.005, 'batch_size': 16, 'warmup_ratio': 0.1, 'num_epoches': 7, 'f1_reward_weight': 0.75, 'reconstruct_reward_weight': 0.25, 'generate_weight': 1.0, 'mle_weight': 0.25}
F1: 0.5304518659057361 
P: 0.5555555555555556 
R: 0.5075187969924813 
-------------------- 
Hyperparams: 
 {'lr': 5e-05, 'batch_size': 16, 'warmup_ratio': 0.1, 'num_epoches': 10, 'f1_reward_weight': 0.75, 'reconstruct_reward_weight': 0.1, 'generate_weight': 1.0, 'mle_weight': 0.5}
F1: 0.5875912403763386 
P: 0.5709219858156028 
R: 0.6052631578947368 
-------------------- 
Hyperparams: 
 {'lr': 5e-06, 'batch_size': 16, 'warmup_ratio': 0.1, 'num_epoches': 5, 'f1_reward_weight': 0.75, 'reconstruct_reward_weight': 0.1, 'generate_weight': 1.0, 'mle_weight': 0.25}
-------------------- 
Hyperparams: 
 {'lr': 0.005, 'batch_size': 16, 'warmup_ratio': 0.1, 'num_epoches': 5, 'f1_reward_weight': 0.75, 'reconstruct_reward_weight': 0.1, 'generate_weight': 1.0, 'mle_weight': 0.25}
-------------------- 
Hyperparams: 
 {'lr': 5e-06, 'batch_size': 16, 'warmup_ratio': 0.1, 'num_epoches': 5, 'f1_reward_weight': 0.75, 'reconstruct_reward_weight': 0.25, 'generate_weight': 1.0, 'mle_weight': 0.5}
-------------------- 
Hyperparams: 
 {'warmup_ratio': 0.1, 'lr': 0.006, 'batch_size': 32, 'num_epoches': 7, 'mle_weight': 1.0, 'generate_weight': 0.75}
F1: 0.5569064761466384 
P: 0.5998619552164064 
R: 0.5352291763673167 
-------------------- 
Hyperparams: 
 {'warmup_ratio': 0.1, 'lr': 0.0005, 'batch_size': 16, 'num_epoches': 5, 'f1_reward_weight': 0.5, 'reconstruct_reward_weight': 0.1, 'generate_weight': 1.0, 'mle_weight': 0.25}
-------------------- 
Hyperparams: 
 {'lr': 5e-06, 'batch_size': 16, 'warmup_ratio': 0.1, 'num_epoches': 10, 'mle_weight': 1.0, 'generate_weight': 0.5}
-------------------- 
Hyperparams: 
 {'lr': 0.004, 'batch_size': 32, 'warmup_ratio': 0.1, 'num_epoches': 5, 'mle_weight': 1.0, 'generate_weight': 0.5}
-------------------- 
Hyperparams: 
 {'lr': 0.002, 'batch_size': 32, 'warmup_ratio': 0.1, 'num_epoches': 5, 'mle_weight': 1.0, 'generate_weight': 0.5}
